{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the GPU to use\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, for our server either \"0\" , \"1\", \"2\" or \"3\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from keras.applications import ResNet50V2, Xception, VGG19, DenseNet121\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend \n",
    "\n",
    "#include the directory with custom functions\n",
    "sys.path.insert(1, '../custom_functions')\n",
    "from train_functions import *\n",
    "from image_generators import get_generator\n",
    "from custom_callbacks import save_pkl, load_pkl\n",
    "from custom_callbacks import modelTracker\n",
    "from custom_callbacks import saveModelCallback\n",
    "from custom_callbacks import EveryEpochSaver\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "warnings.simplefilter('ignore',  DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "#Verifying the version of tensorflow\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_dir': '../../datasets/dataset_mixed/train_flipped/',\n",
       " 'model_name': 'cv_prod_test',\n",
       " 'all_models_dir': '../../models/',\n",
       " 'pretrained_model_path': '',\n",
       " 'cross_validation': {'dataframes_dir': '../../datasets/dataset_mixed/crossval_10',\n",
       "  'used': False,\n",
       "  'folds': 1},\n",
       " 'dataframe_path': '../../datasets/dataset_mixed/train_flipped/df_Forgetful_Fabio.csv',\n",
       " 'training_is_finised': False,\n",
       " 'image_size': 224,\n",
       " 'opt_dict': {'optimizer_type': 'SGD',\n",
       "  'momentum': 0.002,\n",
       "  'learning_rate': 0.005,\n",
       "  'nesterov': True},\n",
       " 'activation': 'sigmoid',\n",
       " 'use_weights': False,\n",
       " 'non_retinas_weight_factor': 1.0,\n",
       " 'reduce_lr_factor': 0.5,\n",
       " 'train_val_ratio': 0.25,\n",
       " 'last_layer_output_dim': 512,\n",
       " 'normalization_mode': 'samplewise',\n",
       " 'class_mode': 'binary',\n",
       " 'last_layer_dropout_rate': 0.9,\n",
       " 'reduce_lr_min': 1e-09,\n",
       " 'epochs': 10,\n",
       " 'keras_model_name': 'resnet50v2',\n",
       " 'reduce_on_plateau_patience': 4,\n",
       " 'reduce_lr_patience': 6,\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'batch_size': 32,\n",
       " 'input_shape': [224, 224, 3],\n",
       " 'trainable_layers': {'from': 50, 'to': 60}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Opening the config file\n",
    "TRAIN_CONFIG_PATH = \"train_config.json\"\n",
    "with open(TRAIN_CONFIG_PATH, \"r\") as read_file:\n",
    "    train_config = json.load(read_file)\n",
    "train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to edit config from this notebook use this cell with train_config[\"key\"] = \"value\" \n",
    "#WARNING: file \"config.json\" will be overwritten\n",
    "\n",
    "#pretrainedModelType should be chosen manually\n",
    "pretrainedModelType = ResNet50V2\n",
    "train_config[\"trainable_layers\"][\"from\"] = 100\n",
    "train_config[\"trainable_layers\"][\"to\"] = 197\n",
    "train_config[\"model_name\"] =\"cv_prod_test\"\n",
    "train_config[\"keras_model_name\"] = pretrainedModelType().name\n",
    "#Turning on or turning off cros-validation\n",
    "train_config[\"cross_validation\"] = {\n",
    "    \"dataframes_dir\": '../../datasets/dataset_mixed/crossval_10',\n",
    "    \"used\": False,\n",
    "    \"folds\": 1 \n",
    "}\n",
    "#path for already trained model. If it is an empty line, no pretrained model is used\n",
    "train_config[\"pretrained_model_path\"]=\"\"\n",
    "\n",
    "with open(TRAIN_CONFIG_PATH, \"w+\") as write_file:\n",
    "    json.dump(train_config, write_file)\n",
    "    \n",
    "#If MODEL_OVERWRITE_MODE is \"on\" than the model will be wirtten in the same dir at each run.\n",
    "#If MODEL_OVERWRITE_MODE is \"off\" the exception will be accerted in the next cell execution \n",
    "MODEL_OVERWRITE_MODE = \"on\"\n",
    "#This line creates variabels with the same names as train_config.keys() and values from train_config\n",
    "locals().update(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding date, time and computer name to the config\n",
    "model_config = make_model_config(train_config)\n",
    "\n",
    "#Creating the model dir inside train_config[\"all_models_dir\"] and several subdirs.\n",
    "model_dir, temp_dataframes_dirs, history_dirs, model_weights_dirs = make_place_for_the_model(model_config,\n",
    "                                                                       MODEL_OVERWRITE_MODE\n",
    "                                                                      )\n",
    "\n",
    "\n",
    "#Defining dataframes.\n",
    "#For cross-validation the dataframes should be prepared in advance and be storeed in \n",
    "#train_config[\"cross_validation\"][\"dataframes_dir\"]\n",
    "#Otherwise train dataframe is randomly spliteed into train and val\n",
    "\n",
    "if train_config[\"cross_validation\"][\"used\"]:\n",
    "    dfs_train, dfs_val = import_kfold_dataframes(train_config)\n",
    "else:\n",
    "    dataframe_train, dataframe_val = create_temp_dfs(dataframe_path,\n",
    "                                                                temp_dataframes_dirs[0], \n",
    "                                                                model_name,\n",
    "                                                                train_val_ratio\n",
    "                                                             )\n",
    "    dfs_train = [dataframe_train]\n",
    "    dfs_val = [dataframe_val]\n",
    "\n",
    "\n",
    "#Defining the normaliztion parameters for generators\n",
    "samplewise_std_normalization, samplewise_center,\\\n",
    "featurewise_std_normalization, featurewise_center,\\\n",
    "rescale = normalization_mode_setter(normalization_mode)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#from keras.utils import plot_model\n",
    "#plot_model(pretrainedModelType(), to_file='model_graphs/DenseNet121.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.optimizers.SGD object at 0x7fe595c4fb70>\n",
      "   0) input_2                          trainable: False\n",
      "   1) conv1_pad                        trainable: False\n",
      "   2) conv1_conv                       trainable: False\n",
      "   3) pool1_pad                        trainable: False\n",
      "   4) pool1_pool                       trainable: False\n",
      "   5) conv2_block1_preact_bn           trainable: False\n",
      "   6) conv2_block1_preact_relu         trainable: False\n",
      "   7) conv2_block1_1_conv              trainable: False\n",
      "   8) conv2_block1_1_bn                trainable: False\n",
      "   9) conv2_block1_1_relu              trainable: False\n",
      "  10) conv2_block1_2_pad               trainable: False\n",
      "  11) conv2_block1_2_conv              trainable: False\n",
      "  12) conv2_block1_2_bn                trainable: False\n",
      "  13) conv2_block1_2_relu              trainable: False\n",
      "  14) conv2_block1_0_conv              trainable: False\n",
      "  15) conv2_block1_3_conv              trainable: False\n",
      "  16) conv2_block1_out                 trainable: False\n",
      "  17) conv2_block2_preact_bn           trainable: False\n",
      "  18) conv2_block2_preact_relu         trainable: False\n",
      "  19) conv2_block2_1_conv              trainable: False\n",
      "  20) conv2_block2_1_bn                trainable: False\n",
      "  21) conv2_block2_1_relu              trainable: False\n",
      "  22) conv2_block2_2_pad               trainable: False\n",
      "  23) conv2_block2_2_conv              trainable: False\n",
      "  24) conv2_block2_2_bn                trainable: False\n",
      "  25) conv2_block2_2_relu              trainable: False\n",
      "  26) conv2_block2_3_conv              trainable: False\n",
      "  27) conv2_block2_out                 trainable: False\n",
      "  28) conv2_block3_preact_bn           trainable: False\n",
      "  29) conv2_block3_preact_relu         trainable: False\n",
      "  30) conv2_block3_1_conv              trainable: False\n",
      "  31) conv2_block3_1_bn                trainable: False\n",
      "  32) conv2_block3_1_relu              trainable: False\n",
      "  33) conv2_block3_2_pad               trainable: False\n",
      "  34) conv2_block3_2_conv              trainable: False\n",
      "  35) conv2_block3_2_bn                trainable: False\n",
      "  36) conv2_block3_2_relu              trainable: False\n",
      "  37) max_pooling2d_4                  trainable: False\n",
      "  38) conv2_block3_3_conv              trainable: False\n",
      "  39) conv2_block3_out                 trainable: False\n",
      "  40) conv3_block1_preact_bn           trainable: False\n",
      "  41) conv3_block1_preact_relu         trainable: False\n",
      "  42) conv3_block1_1_conv              trainable: False\n",
      "  43) conv3_block1_1_bn                trainable: False\n",
      "  44) conv3_block1_1_relu              trainable: False\n",
      "  45) conv3_block1_2_pad               trainable: False\n",
      "  46) conv3_block1_2_conv              trainable: False\n",
      "  47) conv3_block1_2_bn                trainable: False\n",
      "  48) conv3_block1_2_relu              trainable: False\n",
      "  49) conv3_block1_0_conv              trainable: False\n",
      "  50) conv3_block1_3_conv              trainable: False\n",
      "  51) conv3_block1_out                 trainable: False\n",
      "  52) conv3_block2_preact_bn           trainable: False\n",
      "  53) conv3_block2_preact_relu         trainable: False\n",
      "  54) conv3_block2_1_conv              trainable: False\n",
      "  55) conv3_block2_1_bn                trainable: False\n",
      "  56) conv3_block2_1_relu              trainable: False\n",
      "  57) conv3_block2_2_pad               trainable: False\n",
      "  58) conv3_block2_2_conv              trainable: False\n",
      "  59) conv3_block2_2_bn                trainable: False\n",
      "  60) conv3_block2_2_relu              trainable: False\n",
      "  61) conv3_block2_3_conv              trainable: False\n",
      "  62) conv3_block2_out                 trainable: False\n",
      "  63) conv3_block3_preact_bn           trainable: False\n",
      "  64) conv3_block3_preact_relu         trainable: False\n",
      "  65) conv3_block3_1_conv              trainable: False\n",
      "  66) conv3_block3_1_bn                trainable: False\n",
      "  67) conv3_block3_1_relu              trainable: False\n",
      "  68) conv3_block3_2_pad               trainable: False\n",
      "  69) conv3_block3_2_conv              trainable: False\n",
      "  70) conv3_block3_2_bn                trainable: False\n",
      "  71) conv3_block3_2_relu              trainable: False\n",
      "  72) conv3_block3_3_conv              trainable: False\n",
      "  73) conv3_block3_out                 trainable: False\n",
      "  74) conv3_block4_preact_bn           trainable: False\n",
      "  75) conv3_block4_preact_relu         trainable: False\n",
      "  76) conv3_block4_1_conv              trainable: False\n",
      "  77) conv3_block4_1_bn                trainable: False\n",
      "  78) conv3_block4_1_relu              trainable: False\n",
      "  79) conv3_block4_2_pad               trainable: False\n",
      "  80) conv3_block4_2_conv              trainable: False\n",
      "  81) conv3_block4_2_bn                trainable: False\n",
      "  82) conv3_block4_2_relu              trainable: False\n",
      "  83) max_pooling2d_5                  trainable: False\n",
      "  84) conv3_block4_3_conv              trainable: False\n",
      "  85) conv3_block4_out                 trainable: False\n",
      "  86) conv4_block1_preact_bn           trainable: False\n",
      "  87) conv4_block1_preact_relu         trainable: False\n",
      "  88) conv4_block1_1_conv              trainable: False\n",
      "  89) conv4_block1_1_bn                trainable: False\n",
      "  90) conv4_block1_1_relu              trainable: False\n",
      "  91) conv4_block1_2_pad               trainable: False\n",
      "  92) conv4_block1_2_conv              trainable: False\n",
      "  93) conv4_block1_2_bn                trainable: False\n",
      "  94) conv4_block1_2_relu              trainable: False\n",
      "  95) conv4_block1_0_conv              trainable: False\n",
      "  96) conv4_block1_3_conv              trainable: False\n",
      "  97) conv4_block1_out                 trainable: False\n",
      "  98) conv4_block2_preact_bn           trainable: False\n",
      "  99) conv4_block2_preact_relu         trainable: False\n",
      " 100) conv4_block2_1_conv              trainable: True\n",
      " 101) conv4_block2_1_bn                trainable: True\n",
      " 102) conv4_block2_1_relu              trainable: True\n",
      " 103) conv4_block2_2_pad               trainable: True\n",
      " 104) conv4_block2_2_conv              trainable: True\n",
      " 105) conv4_block2_2_bn                trainable: True\n",
      " 106) conv4_block2_2_relu              trainable: True\n",
      " 107) conv4_block2_3_conv              trainable: True\n",
      " 108) conv4_block2_out                 trainable: True\n",
      " 109) conv4_block3_preact_bn           trainable: True\n",
      " 110) conv4_block3_preact_relu         trainable: True\n",
      " 111) conv4_block3_1_conv              trainable: True\n",
      " 112) conv4_block3_1_bn                trainable: True\n",
      " 113) conv4_block3_1_relu              trainable: True\n",
      " 114) conv4_block3_2_pad               trainable: True\n",
      " 115) conv4_block3_2_conv              trainable: True\n",
      " 116) conv4_block3_2_bn                trainable: True\n",
      " 117) conv4_block3_2_relu              trainable: True\n",
      " 118) conv4_block3_3_conv              trainable: True\n",
      " 119) conv4_block3_out                 trainable: True\n",
      " 120) conv4_block4_preact_bn           trainable: True\n",
      " 121) conv4_block4_preact_relu         trainable: True\n",
      " 122) conv4_block4_1_conv              trainable: True\n",
      " 123) conv4_block4_1_bn                trainable: True\n",
      " 124) conv4_block4_1_relu              trainable: True\n",
      " 125) conv4_block4_2_pad               trainable: True\n",
      " 126) conv4_block4_2_conv              trainable: True\n",
      " 127) conv4_block4_2_bn                trainable: True\n",
      " 128) conv4_block4_2_relu              trainable: True\n",
      " 129) conv4_block4_3_conv              trainable: True\n",
      " 130) conv4_block4_out                 trainable: True\n",
      " 131) conv4_block5_preact_bn           trainable: True\n",
      " 132) conv4_block5_preact_relu         trainable: True\n",
      " 133) conv4_block5_1_conv              trainable: True\n",
      " 134) conv4_block5_1_bn                trainable: True\n",
      " 135) conv4_block5_1_relu              trainable: True\n",
      " 136) conv4_block5_2_pad               trainable: True\n",
      " 137) conv4_block5_2_conv              trainable: True\n",
      " 138) conv4_block5_2_bn                trainable: True\n",
      " 139) conv4_block5_2_relu              trainable: True\n",
      " 140) conv4_block5_3_conv              trainable: True\n",
      " 141) conv4_block5_out                 trainable: True\n",
      " 142) conv4_block6_preact_bn           trainable: True\n",
      " 143) conv4_block6_preact_relu         trainable: True\n",
      " 144) conv4_block6_1_conv              trainable: True\n",
      " 145) conv4_block6_1_bn                trainable: True\n",
      " 146) conv4_block6_1_relu              trainable: True\n",
      " 147) conv4_block6_2_pad               trainable: True\n",
      " 148) conv4_block6_2_conv              trainable: True\n",
      " 149) conv4_block6_2_bn                trainable: True\n",
      " 150) conv4_block6_2_relu              trainable: True\n",
      " 151) max_pooling2d_6                  trainable: True\n",
      " 152) conv4_block6_3_conv              trainable: True\n",
      " 153) conv4_block6_out                 trainable: True\n",
      " 154) conv5_block1_preact_bn           trainable: True\n",
      " 155) conv5_block1_preact_relu         trainable: True\n",
      " 156) conv5_block1_1_conv              trainable: True\n",
      " 157) conv5_block1_1_bn                trainable: True\n",
      " 158) conv5_block1_1_relu              trainable: True\n",
      " 159) conv5_block1_2_pad               trainable: True\n",
      " 160) conv5_block1_2_conv              trainable: True\n",
      " 161) conv5_block1_2_bn                trainable: True\n",
      " 162) conv5_block1_2_relu              trainable: True\n",
      " 163) conv5_block1_0_conv              trainable: True\n",
      " 164) conv5_block1_3_conv              trainable: True\n",
      " 165) conv5_block1_out                 trainable: True\n",
      " 166) conv5_block2_preact_bn           trainable: True\n",
      " 167) conv5_block2_preact_relu         trainable: True\n",
      " 168) conv5_block2_1_conv              trainable: True\n",
      " 169) conv5_block2_1_bn                trainable: True\n",
      " 170) conv5_block2_1_relu              trainable: True\n",
      " 171) conv5_block2_2_pad               trainable: True\n",
      " 172) conv5_block2_2_conv              trainable: True\n",
      " 173) conv5_block2_2_bn                trainable: True\n",
      " 174) conv5_block2_2_relu              trainable: True\n",
      " 175) conv5_block2_3_conv              trainable: True\n",
      " 176) conv5_block2_out                 trainable: True\n",
      " 177) conv5_block3_preact_bn           trainable: True\n",
      " 178) conv5_block3_preact_relu         trainable: True\n",
      " 179) conv5_block3_1_conv              trainable: True\n",
      " 180) conv5_block3_1_bn                trainable: True\n",
      " 181) conv5_block3_1_relu              trainable: True\n",
      " 182) conv5_block3_2_pad               trainable: True\n",
      " 183) conv5_block3_2_conv              trainable: True\n",
      " 184) conv5_block3_2_bn                trainable: True\n",
      " 185) conv5_block3_2_relu              trainable: True\n",
      " 186) conv5_block3_3_conv              trainable: True\n",
      " 187) conv5_block3_out                 trainable: True\n",
      " 188) post_bn                          trainable: True\n",
      " 189) post_relu                        trainable: True\n",
      " 190) global_average_pooling2d_1       trainable: True\n",
      " 191) dropout_1                        trainable: True\n",
      " 192) dense_1                          trainable: True\n",
      " 193) batch_normalization_1            trainable: True\n",
      " 194) activation_1                     trainable: True\n",
      " 195) dropout_2                        trainable: True\n",
      " 196) dense_2                          trainable: True\n"
     ]
    }
   ],
   "source": [
    "#Importing the pretrained model. If pretrained_model_path is empty,\n",
    "# the one from Keras library is used, with several layers being appended\n",
    "model = make_model(train_config, pretrainedModelType)\n",
    "for n, layer in enumerate(model.layers):\n",
    "    print(\" %3d) %-30s   trainable: %s\" % (n,str(layer.name), layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,610,497\n"
     ]
    }
   ],
   "source": [
    "#Number of trainable parameters\n",
    "trainable_count = int(\n",
    "    np.sum([backend.count_params(p) for p in set(model.trainable_weights)]))\n",
    "non_trainable_count = int(\n",
    "    np.sum([backend.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "print('{:,}'.format(trainable_count) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation itteration number 0\n",
      "\n",
      "Creating train generator\n",
      "Found 1083 validated image filenames belonging to 2 classes.\n",
      "Train class_indices:  {'non-retina': 0, 'retina': 1}\n",
      "train_class_weights:  {1: 1.0, 0: 0.9}\n",
      "train_class_weights to use:  {1: 1.0, 0: 1.0}\n",
      "\n",
      "Creating val generator\n",
      "Found 362 validated image filenames belonging to 2 classes.\n",
      "Val class_indices:  {'non-retina': 0, 'retina': 1}\n",
      "\n",
      "Generators for metrics computing\n",
      "<keras.optimizers.SGD object at 0x7fe58e1ae048>\n",
      "Found 1083 validated image filenames belonging to 2 classes.\n",
      "Found 362 validated image filenames belonging to 2 classes.\n",
      "\n",
      "Model \"cv_prod_test\" is being trained.\n",
      "Class mode is \"binary\".\n",
      "The model is contained in the directory: ../../models/cv_prod_test \n",
      "\n",
      "Epoch 1/10\n",
      "Train--Val loss: 0.705298 -- 0.704469, Train--Val ROCAUC: 0.518077 -- 0.518049\n",
      "Epoch 2/10\n",
      "Model with best val_ROCAUC is saved\n",
      "Train--Val loss: 0.688351 -- 0.689529, Train--Val ROCAUC: 0.557303 -- 0.563853\n",
      "Epoch 3/10\n",
      "Model with best val_ROCAUC is saved\n",
      "Train--Val loss: 0.673731 -- 0.673685, Train--Val ROCAUC: 0.613950 -- 0.652843\n",
      "Epoch 4/10\n",
      "Model with best val_ROCAUC is saved\n",
      "Train--Val loss: 0.677045 -- 0.689171, Train--Val ROCAUC: 0.626011 -- 0.665993\n",
      "Epoch 5/10\n",
      "Train--Val loss: 0.694004 -- 0.714375, Train--Val ROCAUC: 0.624011 -- 0.662197\n",
      "Epoch 6/10\n",
      "Model with best val_ROCAUC is saved\n",
      "Train--Val loss: 0.677886 -- 0.703664, Train--Val ROCAUC: 0.654796 -- 0.684425\n",
      "Epoch 7/10\n",
      "Model with best val_ROCAUC is saved\n",
      "Train--Val loss: 0.687133 -- 0.709073, Train--Val ROCAUC: 0.650778 -- 0.727963\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Train--Val loss: 0.683246 -- 0.695549, Train--Val ROCAUC: 0.650511 -- 0.708000\n",
      "Epoch 9/10\n",
      "Train--Val loss: 0.675583 -- 0.697313, Train--Val ROCAUC: 0.670271 -- 0.705459\n",
      "Epoch 10/10\n",
      "Train--Val loss: 0.670623 -- 0.680849, Train--Val ROCAUC: 0.665695 -- 0.712746\n",
      "\n",
      "************************************************************************ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training procedure\n",
    "\n",
    "with open(os.path.join(model_dir,\"model_config.json\"), \"w+\") as write_file:\n",
    "    json.dump(model_config, write_file)\n",
    "     \n",
    "if train_config[\"cross_validation\"][\"used\"]:\n",
    "    number_of_cycles = cross_validation[\"folds\"]\n",
    "else:\n",
    "    number_of_cycles = 1\n",
    "    \n",
    "for k in range(cross_validation[\"folds\"]):\n",
    "    \n",
    "    print(\"Cross-validation itteration number\", k)\n",
    "    \n",
    "    #Defining the dir where to save currnet progress\n",
    "    if train_config[\"cross_validation\"][\"used\"]:\n",
    "        split_dir = os.path.join(model_dir, \"_\".join([\"split\", str(k)]))\n",
    "        if not os.path.exists(split_dir):\n",
    "            raise Exception(\"No split path!\")\n",
    "    else:\n",
    "        split_dir = model_dir\n",
    "        \n",
    "    #Selecting dataframes  \n",
    "    df_train = dfs_train[k] \n",
    "    df_val = dfs_val[k] \n",
    "   \n",
    "    print(\"\\nCreating train generator\")\n",
    "    \n",
    "    #Defining train and val generators\n",
    "    train_generator = get_generator(train_config, df_train, shuffle = True,  augmentation = True)\n",
    "    train_class_weights = get_class_weigts(train_generator)\n",
    "    train_class_weights[train_generator.class_indices[\"non-retina\"]] *= non_retinas_weight_factor \n",
    "    print('Train class_indices: ', train_generator.class_indices)\n",
    "    print('train_class_weights: ', train_class_weights)\n",
    "    if not use_weights:\n",
    "        train_class_weights = {\n",
    "            1: 1.,\n",
    "            0: 1.\n",
    "        }\n",
    "    print('train_class_weights to use: ', train_class_weights)\n",
    "    print(\"\\nCreating val generator\")\n",
    "    val_generator = get_generator(train_config, df_val , shuffle = False,  augmentation = True)\n",
    "    print('Val class_indices: ', val_generator.class_indices)\n",
    "    \n",
    "    print(\"\\nGenerators for metrics computing\")\n",
    "        \n",
    "    #Defining the model \n",
    "    model = make_model(train_config, pretrainedModelType)\n",
    "    \n",
    "    #Forming callback list\n",
    "    #Note, that to compute the metric two additional generators required (without augmentation)\n",
    "    metrics_train_generator = get_generator(train_config, df_train, shuffle=False, augmentation=True)\n",
    "    metrics_val_generator = get_generator(train_config, df_val, shuffle=False, augmentation=False)\n",
    "    model_tracker = modelTracker(history_dirs[k],\n",
    "                             metrics_train_generator,\n",
    "                             metrics_val_generator,\n",
    "                             model_name,\n",
    "                             split_dir,\n",
    "                             monitor = \"val_ROCAUC\"\n",
    "                            )\n",
    "    EpochSaver = EveryEpochSaver(model_name, model_weights_dirs[k])\n",
    "    last_model_path = os.path.join(split_dir,\"last_\" + model_name + '.h5')\n",
    "    best_val_acc_model_path = os.path.join(split_dir,\"keras_best_val_acc_\" + model_name + '.h5') \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=reduce_lr_patience, \n",
    "                                            verbose=1, \n",
    "                                            factor=reduce_lr_factor, \n",
    "                                            min_lr=reduce_lr_min)   \n",
    "    callbacks_list = [learning_rate_reduction, model_tracker, EpochSaver]\n",
    "    \n",
    "       \n",
    "    #Defining the steps per each epoch\n",
    "    train_samples_number = df_train.shape[0]\n",
    "    steps_per_epoch = math.ceil(train_samples_number // batch_size)\n",
    "    \n",
    "    val_samples_number = df_val.shape[0]\n",
    "    val_steps = math.ceil(val_samples_number // batch_size)\n",
    "\n",
    "    #Starting the training\n",
    "    print(\"\\nModel \\\"%s\\\" is being trained.\"% (model_name))\n",
    "    print(\"Class mode is \\\"%s\\\".\"% train_generator.class_mode)\n",
    "    print(\"The model is contained in the directory: %s \\n\" % split_dir)\n",
    "    history = model.fit_generator( train_generator,\n",
    "                                steps_per_epoch= steps_per_epoch,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=val_steps,\n",
    "                                callbacks=callbacks_list,\n",
    "                                epochs=epochs,\n",
    "                                class_weight=train_class_weights,\n",
    "                                verbose=3)\n",
    "    \n",
    "    #Saving last model and the history\n",
    "    model.save(last_model_path)\n",
    "    save_pkl(history.history, os.path.join(history_dirs[k], 'history_Keras.pkl')) \n",
    "    \n",
    "    print(\"\\n************************************************************************ \\n\")\n",
    "    \n",
    "model_config_path = os.path.join(all_models_dir, model_name, \"_\".join([model_name, \"config.json\"]))\n",
    "model_config[\"training_is_finished\"] = True\n",
    "with open(model_config_path, \"w+\") as write_file:\n",
    "    json.dump(model_config,write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eye_project_venv",
   "language": "python",
   "name": "eye_project_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
